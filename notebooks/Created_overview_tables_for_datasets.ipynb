{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb39ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "if not \"changed_working_directory\" in locals():\n",
    "    changed_working_directory = True\n",
    "    os.chdir(pathlib.Path().resolve().parent)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tabGAN import TabGAN\n",
    "from src import constants as const\n",
    "import helpers\n",
    "from v2_hp_tuning import fetch_hp_info\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "imports_path = \"src//imports.ipynb\"\n",
    "\n",
    "%run \"$imports_path\"\n",
    "\n",
    "if const.dir.project() != os.getcwd():\n",
    "    raise ValueError(\"Project directory not the same as in consts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    categories=cats,  # Categories per feature\n",
    ")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame({\"a\": [\"a\", \"b\", \"c\", \"a\", \"b\"]})\n",
    "d2 = pd.DataFrame({\"a\": [\"a\", \"b\", \"c\", \"a\", \"e\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e10e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit(d1.append(d2, ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da792ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0398c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(const.dir.data_comparison(), \"news_edited.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6dd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9dbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([\"d\", \"a\", \"a\", \"c\", \"b\", \"c\"]).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340813c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1376526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories_or_range_from_df(df, round_decimals=None, round_significant_figures=2,\n",
    "                                   round_decimals_numeric=2):\n",
    "    df = df[sorted(df.columns, key=str.casefold)]\n",
    "    #print(df.dtypes)\n",
    "    df_overview_columns = pd.DataFrame({\"Column\": df.columns, \"Values (numerical range or categories)\": None})\n",
    "    column_dtypes = df.dtypes\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if column_dtypes[i] == \"object\":\n",
    "            unique_categories = np.sort(df[column].unique())\n",
    "            counts_categories = df[column].value_counts()\n",
    "            percentage_categories = (counts_categories / counts_categories.sum() * 100)\n",
    "            if round_significant_figures is not None:\n",
    "                percentage_categories = percentage_categories.apply(lambda val: float('%.1g' % val))\n",
    "                percentage_categories = percentage_categories.apply(lambda val: int(val) if val % 1 == 0 else val)\n",
    "            elif round_decimals is not None:\n",
    "                percentage_categories = percentage_categories.round(decimals=round_decimals)\n",
    "            dict_category_percentages = {ix: val for ix,val in zip(percentage_categories.index, percentage_categories)}\n",
    "            str_unique_categories = \", \".join(f\"{cat} ({dict_category_percentages[cat]}%)\"for cat in unique_categories)\n",
    "            df_overview_columns.loc[i, \"Values (numerical range or categories)\"] = str_unique_categories\n",
    "    #         print(str_unique_categories)\n",
    "        else:\n",
    "            low = df[column].min().round(round_decimals_numeric)\n",
    "            high = df[column].max().round(round_decimals_numeric)\n",
    "            df_overview_columns.loc[i, \"Values (numerical range or categories)\"] = f\"[{low}, {high}]\"\n",
    "    #         print(f\"[{df[column].min()}, {df[column].max()}]\")\n",
    "    return df_overview_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfdb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_categories_or_range_from_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7526a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_caption_for_column_overview_table(dataset_name):\n",
    "    return (f\"Overview of each column in the {dataset_name} dataset. For numerical columns the value range is reported,\"\n",
    "            \" while for discrete columns the categories along with percentages are reported. The percentages for all\"\n",
    "            \" categories of a single discrete column sum to $1$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8c65ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: Slope. Value: 8.0. n_curr_references: 51\n",
      "Column: Slope. Value: 9.0. n_curr_references: 55\n",
      "Column: Slope. Value: 10.0. n_curr_references: 57\n",
      "Column: Slope. Value: 11.0. n_curr_references: 59\n",
      "Column: Slope. Value: 12.0. n_curr_references: 57\n",
      "Column: Slope. Value: 13.0. n_curr_references: 57\n",
      "Column: Slope. Value: 14.0. n_curr_references: 53\n",
      "Column: Horizontal_Distance_To_Hydrology. Value: 30.0. n_curr_references: 59\n",
      "Column: Vertical_Distance_To_Hydrology. Value: 0.0. n_curr_references: 66\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(const.dir.data_comparison(), \"covtype_edited.csv\"))\n",
    "from tabGAN import TabGAN\n",
    "tg = TabGAN(df, quantile_transformation_int=True, print_values_where_qtr_is_applied=True, qtr_lbound_apply=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25997ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wilderness_Area                       object\n",
       "Soil_Type                             object\n",
       "Elevation                              int64\n",
       "Aspect                                 int64\n",
       "Slope                                  int64\n",
       "Horizontal_Distance_To_Hydrology       int64\n",
       "Vertical_Distance_To_Hydrology         int64\n",
       "Horizontal_Distance_To_Roadways        int64\n",
       "Hillshade_9am                          int64\n",
       "Hillshade_Noon                         int64\n",
       "Hillshade_3pm                          int64\n",
       "Horizontal_Distance_To_Fire_Points     int64\n",
       "Cover_Type                            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49d312f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoverType2    283301\n",
       "CoverType1    211840\n",
       "CoverType3     35754\n",
       "CoverType7     20510\n",
       "CoverType6     17367\n",
       "CoverType5      9493\n",
       "CoverType4      2747\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Cover_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2686675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(const.dir.data_comparison(), \"creditcard_edited.csv\"))\n",
    "from tabGAN import TabGAN\n",
    "tg = TabGAN(df, quantile_transformation_int=True, quantile_rand_transformation=True, print_values_where_qtr_is_applied=True,\n",
    "           qtr_lbound_apply=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68141d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4a3c075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class0    284315\n",
       "Class1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a48bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(const.dir.data_comparison(), \"creditcard_edited.csv\"))\n",
    "from tabGAN import TabGAN\n",
    "tg = TabGAN(df, quantile_transformation_int=True, print_values_where_qtr_is_applied=True, qtr_lbound_apply=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116167d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_column_info_covtype = get_categories_or_range_from_df(pd.read_csv(os.path.join(const.dir.data_comparison(), \"covtype_edited.csv\")))\n",
    "dataset_name = \"Covertype\"\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    print(df_column_info_covtype.to_latex(caption=create_caption_for_column_overview_table(dataset_name),\n",
    "                                     label=f\"tab:column_overview_{dataset_name}\",\n",
    "                                      index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd28a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_column_info_creditcard = get_categories_or_range_from_df(pd.read_csv(os.path.join(const.dir.data_comparison(), \"creditcard_edited.csv\")),)\n",
    "dataset_name = \"Creditcard\"\n",
    "print(df_column_info_creditcard.to_latex(caption=create_caption_for_column_overview_table(dataset_name),\n",
    "                                     label=f\"tab:column_overview_{dataset_name}\",\n",
    "                                      index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1234f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Overview of each column in the Online News Popularity dataset. For numerical columns the value range is reported, while for discrete columns the categories along with percentages are reported. The percentages for all categories of a single discrete column sum to $1$}\n",
      "\\label{tab:column_overview_Online News Popularity}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "                      Column &                                                                 Values (numerical range or categories) \\\\\n",
      "\\midrule\n",
      "abs\\_title\\_sentiment\\_polarity &                                                                                             [0.0, 1.0] \\\\\n",
      "      abs\\_title\\_subjectivity &                                                                                             [0.0, 0.5] \\\\\n",
      "        average\\_token\\_length &                                                                                            [0.0, 8.04] \\\\\n",
      "       avg\\_negative\\_polarity &                                                                                            [-1.0, 0.0] \\\\\n",
      "       avg\\_positive\\_polarity &                                                                                             [0.0, 1.0] \\\\\n",
      "                data\\_channel &                  bus (20\\%), entertainment (20\\%), lifestyle (20\\%), socmed (6\\%), tech (20\\%), world (20\\%) \\\\\n",
      "  global\\_rate\\_negative\\_words &                                                                                            [0.0, 0.18] \\\\\n",
      "  global\\_rate\\_positive\\_words &                                                                                            [0.0, 0.16] \\\\\n",
      "   global\\_sentiment\\_polarity &                                                                                          [-0.39, 0.73] \\\\\n",
      "         global\\_subjectivity &                                                                                             [0.0, 1.0] \\\\\n",
      "                  is\\_weekend &                                                                                    no (90\\%), yes (10\\%) \\\\\n",
      "                  kw\\_avg\\_avg &                                                                                        [0.0, 43567.66] \\\\\n",
      "                  kw\\_avg\\_max &                                                                                        [0.0, 843300.0] \\\\\n",
      "                  kw\\_avg\\_min &                                                                                       [-1.0, 42827.86] \\\\\n",
      "                  kw\\_max\\_avg &                                                                                        [0.0, 298400.0] \\\\\n",
      "                  kw\\_max\\_max &                                                                                        [0.0, 843300.0] \\\\\n",
      "                  kw\\_max\\_min &                                                                                        [0.0, 298400.0] \\\\\n",
      "                  kw\\_min\\_avg &                                                                                        [-1.0, 3613.04] \\\\\n",
      "                  kw\\_min\\_max &                                                                                        [0.0, 843300.0] \\\\\n",
      "                  kw\\_min\\_min &                                                                                          [-1.0, 377.0] \\\\\n",
      "                      LDA\\_00 &                                                                                            [0.0, 0.93] \\\\\n",
      "                      LDA\\_01 &                                                                                            [0.0, 0.93] \\\\\n",
      "                      LDA\\_02 &                                                                                            [0.0, 0.92] \\\\\n",
      "                      LDA\\_03 &                                                                                            [0.0, 0.93] \\\\\n",
      "                      LDA\\_04 &                                                                                            [0.0, 0.93] \\\\\n",
      "       max\\_negative\\_polarity &                                                                                            [-1.0, 0.0] \\\\\n",
      "       max\\_positive\\_polarity &                                                                                             [0.0, 1.0] \\\\\n",
      "       min\\_negative\\_polarity &                                                                                            [-1.0, 0.0] \\\\\n",
      "       min\\_positive\\_polarity &                                                                                             [0.0, 1.0] \\\\\n",
      "    n\\_non\\_stop\\_unique\\_tokens &                                                                                           [0.0, 650.0] \\\\\n",
      "            n\\_non\\_stop\\_words &                                                                                          [0.0, 1042.0] \\\\\n",
      "            n\\_tokens\\_content &                                                                                          [0.0, 8474.0] \\\\\n",
      "              n\\_tokens\\_title &                                                                                            [2.0, 23.0] \\\\\n",
      "             n\\_unique\\_tokens &                                                                                           [0.0, 701.0] \\\\\n",
      "                   num\\_hrefs &                                                                                           [0.0, 304.0] \\\\\n",
      "                    num\\_imgs &                                                                                           [0.0, 128.0] \\\\\n",
      "                num\\_keywords &                                                                                            [1.0, 10.0] \\\\\n",
      "              num\\_self\\_hrefs &                                                                                           [0.0, 116.0] \\\\\n",
      "                  num\\_videos &                                                                                            [0.0, 91.0] \\\\\n",
      "         rate\\_negative\\_words &                                                                                             [0.0, 1.0] \\\\\n",
      "         rate\\_positive\\_words &                                                                                             [0.0, 1.0] \\\\\n",
      "  self\\_reference\\_avg\\_sharess &                                                                                        [0.0, 843300.0] \\\\\n",
      "   self\\_reference\\_max\\_shares &                                                                                        [0.0, 843300.0] \\\\\n",
      "   self\\_reference\\_min\\_shares &                                                                                        [0.0, 843300.0] \\\\\n",
      "                      shares &                                                                                            [1, 843300] \\\\\n",
      "                   timedelta &                                                                                           [8.0, 731.0] \\\\\n",
      "    title\\_sentiment\\_polarity &                                                                                            [-1.0, 1.0] \\\\\n",
      "          title\\_subjectivity &                                                                                             [0.0, 1.0] \\\\\n",
      "                     weekday & Friday (10\\%), Monday (20\\%), Saturday (6\\%), Sunday (7\\%), Thursday (20\\%), Tuesday (20\\%), Wednesday (20\\%) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_column_info_news = get_categories_or_range_from_df(pd.read_csv(os.path.join(const.dir.data_comparison(), \"news_edited.csv\")))\n",
    "dataset_name = \"Online News Popularity\"\n",
    "with pd.option_context(\"max_colwidth\", 200):\n",
    "    print(df_column_info_news.to_latex(caption=create_caption_for_column_overview_table(dataset_name),\n",
    "                                     label=f\"tab:column_overview_{dataset_name}\",\n",
    "                                      index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intrusion = pd.read_csv(os.path.join(const.dir.data_comparison(), \"kddcup (3).data\"),\n",
    "                names=['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
    "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
    "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
    "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
    "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
    "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
    "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "       'dst_host_srv_rerror_rate', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d063e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "intrusion_edited = intrusion\n",
    "intrusion_edited[\"logged_in\"] = np.where(intrusion[\"logged_in\"], \"Yes\", \"No\")\n",
    "intrusion_edited[\"is_guest_login\"] = np.where(intrusion[\"is_guest_login\"], \"Yes\", \"No\")\n",
    "intrusion_edited[\"land\"] = np.where(intrusion[\"land\"], \"Yes\", \"No\")\n",
    "intrusion_edited[\"root_shell\"] = np.where(intrusion[\"root_shell\"], \"Yes\", \"No\")\n",
    "intrusion_edited[\"intrusion\"] = np.where(intrusion[\"class\"] == \"normal.\", \"No\", \"Yes\")\n",
    "intrusion_edited = intrusion_edited.drop(\"class\", axis=1)\n",
    "intrusion_edited = intrusion.dropna()\n",
    "intrusion_edited = intrusion_edited.iloc[np.random.choice(np.arange(intrusion_edited.shape[0]), size=300000, replace=False),\n",
    "                                         :]\n",
    "intrusion_edited.to_csv(os.path.join(const.dir.data_comparison(), \"intrusion_edited.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9259a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column, ty in zip(intrusion_edited.columns, intrusion_edited.dtypes):\n",
    "    print(column, ty, intrusion_edited[column].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
