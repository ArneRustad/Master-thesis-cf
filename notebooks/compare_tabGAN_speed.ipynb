{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bcb2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "if not \"changed_working_directory\" in locals():\n",
    "    changed_working_directory = True\n",
    "    os.chdir(pathlib.Path().resolve().parent)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a804ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabGAN import TabGAN, TabGAN2\n",
    "from src import constants as const\n",
    "import helpers\n",
    "import utils.timer\n",
    "from utils.tictoc import *\n",
    "from utils.timer import Timer\n",
    "\n",
    "imports_path = \"src//imports.ipynb\"\n",
    "%run \"$imports_path\"\n",
    "\n",
    "if const.dir.project() != os.getcwd():\n",
    "    raise ValueError(\"Project directory not the same as in consts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711c68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_path = os.path.join(const.dir.data(), \"df_adult_edited_train.csv\")\n",
    "dataset_test_path = os.path.join(const.dir.data(), \"df_adult_edited_test.csv\")\n",
    "\n",
    "data_train = pd.read_csv(dataset_train_path)\n",
    "data_test = pd.read_csv(dataset_test_path)\n",
    "discrete_columns = data_train.columns[data_train.dtypes == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0182e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_critic = 10\n",
    "opt_lr = 0.002\n",
    "adam_beta1 = 0.5\n",
    "noise_discrete_unif_max = 0\n",
    "\n",
    "batch_size = 500\n",
    "ckpt_every = 1\n",
    "loss_plot_update_every = 10\n",
    "\n",
    "timer_path = os.path.join(const.dir.timers(), \"timer_tabGAN_speed.pkl\")\n",
    "retrain = True\n",
    "\n",
    "if not os.path.exists(timer_path):\n",
    "    timer = Timer()\n",
    "    timer.save(timer_path)\n",
    "    del timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3400781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function(experimental_compile=True)\n",
    "def add(a, b):\n",
    "    return a+b\n",
    "\n",
    "add(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_use=False\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=False\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe8d3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=False, tf_data_prefetch=False, tf_data_cache=False, tf_make_graph=True, jit_compile=False: 526.192 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=False\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "765bbda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=False, tf_data_cache=False, tf_make_graph=True, jit_compile=False: 563.776 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6e39c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=False, tf_make_graph=True, jit_compile=False: 572.008 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdb05926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=True, tf_make_graph=True, jit_compile=False: 559.528 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=True\n",
    "tf_make_graph=True\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bb8000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=False, tf_data_prefetch=False, tf_data_cache=False, tf_make_graph=True, jit_compile=True: 311.813 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=False\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bbc887a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=False, tf_data_cache=False, tf_make_graph=True, jit_compile=True: 338.345 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7deb2050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=False, tf_make_graph=True, jit_compile=True: 337.638 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a75ae5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=True, tf_make_graph=True, jit_compile=True: 345.982 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=True\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d9711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=True, tf_make_graph=True, jit_compile=True: 344.167 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=True\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf23d7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=True, tf_make_graph=True, jit_compile=True: 386.326 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=True\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88d49f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_qtr2 = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=False, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "08e726b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile,\n",
    "               tf_data_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8004941",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = tg_qtr2\n",
    "@tf.function(experimental_compile=False)\n",
    "def run_epoch_numpy():\n",
    "    for batch in range(int(30000 / 500)):\n",
    "        #a = iterator.get_next()\n",
    "        #a = next(iterator)\n",
    "        ix = np.random.randint(low=0, high=self.nrow, size=500)\n",
    "        a = [self.data_num_scaled_cast[ix], self.data_discrete_oh_cast[ix]]\n",
    "        \n",
    "@tf.function(experimental_compile=False)\n",
    "def run_epoch_numpy(iterator):\n",
    "    for batch in range(int(30000 / 500)):\n",
    "        #a = iterator.get_next()\n",
    "        a = next(iterator)\n",
    "        \n",
    "def run_normal():\n",
    "    for b in data_processed:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24ebc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = tf.data.Dataset.zip(\n",
    "    (tf.data.Dataset.from_tensor_slices(tf.cast(tg_qtr.data_num, dtype=tf.float32)),\n",
    "     tf.data.Dataset.from_tensor_slices(tf.cast(tg_qtr.data_discrete_oh, dtype=tf.float32))\n",
    "     )\n",
    ")\n",
    "data_processed = data_processed.shuffle(buffer_size=data_train.shape[0])\n",
    "data_processed = data_processed.repeat(n_epochs).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a594dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99 comsuming_time 7.5149\n"
     ]
    }
   ],
   "source": [
    "num_epoch=100\n",
    "iterator = iter(tg_qtr.data_processed)\n",
    "t1 = time.time()\n",
    "run_normal()\n",
    "t2 = time.time()\n",
    "print('epoch %d comsuming_time %.4f'%(epoch,t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "310d6c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for jit_compile=True: 436.841 seconds\n"
     ]
    }
   ],
   "source": [
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=True)\n",
    "\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(\"jit_compile=True\")\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True,\n",
    "             progress_bar=True)\n",
    "    timer_tabGAN.stop(\"jit_compile=True\")\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c87dcacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518136797897509"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer_tabGAN = utils.timer.load(timer_path)\n",
    "timer_tabGAN.elapsed_time[\"jit_compile=True\"] / timer_tabGAN.elapsed_time[\"jit_compile=False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b07e77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tabGAN2, jit_compile=False: 334.257 seconds\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False,\n",
    "                 tf_make_train_step_graph=False)\n",
    "\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(\"tabGAN2, jit_compile=False\")\n",
    "    %lprun -f tg_qtr2.train_step_func tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(\"tabGAN2, jit_compile=False\")\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80beb4f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17156/4106234316.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhei\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperimental_compile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17156/4106234316.py\u001b[0m in \u001b[0;36mab\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhei\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperimental_compile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Jaaaaaa\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "class ab():\n",
    "    def __init__(self, hei):\n",
    "        print(hei)\n",
    "        self.hei = True\n",
    "    @tf.function(experimental_compile=self.hei)\n",
    "    def p():\n",
    "        print(\"Jaaaaaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fbc68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92b172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "614e738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tabGAN2, jit_compile=False: 303.208 seconds\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False,\n",
    "                 tf_make_train_step_graph=False, use_tf_data=False)\n",
    "\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(\"tabGAN2, jit_compile=False\")\n",
    "    %lprun -f tg_qtr2.train_step_func tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(\"tabGAN2, jit_compile=False\")\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e19d57b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 327.493996 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False)\n",
    "\n",
    "tic()\n",
    "tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2503176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 574.917239 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False)\n",
    "\n",
    "tic()\n",
    "tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd7dfc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 572.547649 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False)\n",
    "\n",
    "tic()\n",
    "tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfa04311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 355.904017 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False)\n",
    "\n",
    "tic()\n",
    "tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c90bafc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6223776223776224"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "356 / 572"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
