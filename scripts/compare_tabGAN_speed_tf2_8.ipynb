{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977dec76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'line_profiler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(pathlib\u001b[38;5;241m.\u001b[39mPath()\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_ext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mline_profiler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2204\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2202\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2204\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\magics\\extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing module name.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malready loaded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m extension is already loaded. To reload it, use:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m module_str)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\extensions.py:92\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m prepended_to_syspath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipython_extension_dir):\n\u001b[1;32m---> 92\u001b[0m         mod \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipython_extension_dir):\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;28mprint\u001b[39m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading extensions from \u001b[39m\u001b[38;5;132;01m{dir}\u001b[39;00m\u001b[38;5;124m is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe recommend managing extensions like any \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother Python packages, in site-packages.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m                   \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39mcompress_user(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipython_extension_dir)))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'line_profiler'"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "if not \"changed_working_directory\" in locals():\n",
    "    changed_working_directory = True\n",
    "    os.chdir(pathlib.Path().resolve().parent)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2070b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from tabGAN import TabGAN, TabGAN2\n",
    "from src import constants as const\n",
    "import helpers\n",
    "import utils.timer\n",
    "from utils.tictoc import *\n",
    "from utils.timer import Timer\n",
    "\n",
    "imports_path = \"src//imports.ipynb\"\n",
    "%run \"$imports_path\"\n",
    "\n",
    "if const.dir.project() != os.getcwd():\n",
    "    raise ValueError(\"Project directory not the same as in consts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b98490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ff77ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_path = os.path.join(const.dir.data(), \"df_adult_edited_train.csv\")\n",
    "dataset_test_path = os.path.join(const.dir.data(), \"df_adult_edited_test.csv\")\n",
    "\n",
    "data_train = pd.read_csv(dataset_train_path)\n",
    "data_test = pd.read_csv(dataset_test_path)\n",
    "discrete_columns = data_train.columns[data_train.dtypes == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb957cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_critic = 10\n",
    "opt_lr = 0.002\n",
    "adam_beta1 = 0.5\n",
    "noise_discrete_unif_max = 0\n",
    "\n",
    "batch_size = 500\n",
    "ckpt_every = 1\n",
    "loss_plot_update_every = 10\n",
    "\n",
    "timer_path = os.path.join(const.dir.timers(), \"timer_tabGAN_speed.pkl\")\n",
    "retrain = True\n",
    "\n",
    "if not os.path.exists(timer_path):\n",
    "    timer = Timer()\n",
    "    timer.save(timer_path)\n",
    "    del timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c74aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function(experimental_compile=True)\n",
    "def add(a, b):\n",
    "    return a+b\n",
    "\n",
    "add(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_use=False\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=False\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0293f3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=False, tf_data_prefetch=False, tf_data_cache=False, tf_make_graph=True, jit_compile=False: 526.192 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=False\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "587e43cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=False, tf_data_cache=False, tf_make_graph=True, jit_compile=False: 563.776 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14e7c7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=False, tf_make_graph=True, jit_compile=False: 572.008 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e259ad48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=True, tf_make_graph=True, jit_compile=False: 559.528 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=True\n",
    "tf_make_graph=True\n",
    "jit_compile=False\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b50bb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=False, tf_data_prefetch=False, tf_data_cache=False, tf_make_graph=True, jit_compile=True: 311.813 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=False\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f778e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c33a4bf8e94f50af22ae9aa5cd60e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Arne\\AppData\\Local\\Temp\\ipykernel_16268\\1371826906.py\", line 19, in <module>\n      tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n    File \"\\\\sambaad.stud.ntnu.no\\arneir\\Master-thesis-cf\\tabGAN\\tabGAN.py\", line 619, in train\n      em_distance_batch, gen_loss_batch = self.train_step(batch_size)\n    File \"\\\\sambaad.stud.ntnu.no\\arneir\\Master-thesis-cf\\tabGAN\\tabGAN.py\", line 462, in train_step_func\n      for i in range(self.n_critic):\n    File \"\\\\sambaad.stud.ntnu.no\\arneir\\Master-thesis-cf\\tabGAN\\tabGAN.py\", line 470, in train_step_func\n      self.train_step_critic(data_batch_real, n_batch)\nNode: 'StatefulPartitionedCall'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_train_step_func_64168]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m timer_tabGAN \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mtimer\u001b[38;5;241m.\u001b[39mload(timer_path)\n\u001b[0;32m     18\u001b[0m timer_tabGAN\u001b[38;5;241m.\u001b[39mstart(timer_key)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mtg_qtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestart_training\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m timer_tabGAN\u001b[38;5;241m.\u001b[39mstop(timer_key)\n\u001b[0;32m     21\u001b[0m timer_tabGAN\u001b[38;5;241m.\u001b[39msave(timer_path)\n",
      "File \u001b[1;32m\\\\sambaad.stud.ntnu.no\\arneir\\Master-thesis-cf\\tabGAN\\tabGAN.py:619\u001b[0m, in \u001b[0;36mTabGAN.train\u001b[1;34m(self, n_epochs, batch_size, restart_training, progress_bar, progress_bar_desc, plot_loss, plot2D_image, plot_time, plot_loss_type, plot_loss_update_every, plot_loss_title, ckpt_every, tf_make_graph, save_dir, filename_plot_loss, filename_plot2D, save_loss, plot_loss_incl_generator_loss, plot2D_num_cols, plot2D_discrete_col, plot2D_color_opacity, plot2D_n_save_img, plot2D_save_int, plot2D_background_func, plot2D_n_img_horiz, plot2D_inv_scale, plot2D_n_test, plot_loss_return, tf_profile_train_step_range, tf_profile_log_dir)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_per_epoch):\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_step\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mepoch, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 619\u001b[0m         em_distance_batch, gen_loss_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     g_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m gen_loss_batch\n\u001b[0;32m    621\u001b[0m     em_distance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m em_distance_batch\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall' defined at (most recent call last):\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Arne\\anaconda3\\envs\\tf2.8\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Arne\\AppData\\Local\\Temp\\ipykernel_16268\\1371826906.py\", line 19, in <module>\n      tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n    File \"\\\\sambaad.stud.ntnu.no\\arneir\\Master-thesis-cf\\tabGAN\\tabGAN.py\", line 619, in train\n      em_distance_batch, gen_loss_batch = self.train_step(batch_size)\n    File \"\\\\sambaad.stud.ntnu.no\\arneir\\Master-thesis-cf\\tabGAN\\tabGAN.py\", line 462, in train_step_func\n      for i in range(self.n_critic):\n    File \"\\\\sambaad.stud.ntnu.no\\arneir\\Master-thesis-cf\\tabGAN\\tabGAN.py\", line 470, in train_step_func\n      self.train_step_critic(data_batch_real, n_batch)\nNode: 'StatefulPartitionedCall'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_train_step_func_64168]"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=False\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e91f8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=False, tf_make_graph=True, jit_compile=True: 337.638 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "860bd653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=True, tf_make_graph=True, jit_compile=True: 345.982 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=True\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f01a5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=True, tf_make_graph=True, jit_compile=True: 344.167 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=True\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f73df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tf_data_use=True, tf_data_prefetch=True, tf_data_cache=True, tf_make_graph=True, jit_compile=True: 386.326 seconds\n"
     ]
    }
   ],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=True\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)\n",
    "\n",
    "timer_key = \"\".join((f\"tf_data_use={tf_data_use}, tf_data_prefetch={tf_data_prefetch}, tf_data_cache={tf_data_cache}, \",\n",
    "                    f\"tf_make_graph={tf_make_graph}, jit_compile={jit_compile}\"\n",
    "                    ))\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(timer_key)\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(timer_key)\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c212f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_qtr2 = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=False, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd2c1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data_use=True\n",
    "tf_data_prefetch=True\n",
    "tf_data_cache=False\n",
    "tf_make_graph=True\n",
    "jit_compile=True\n",
    "\n",
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=tf_data_use, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile,\n",
    "               tf_data_shuffle=False)\n",
    "\n",
    "tg_qtr2 = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max,\n",
    "                tf_data_use=False, tf_data_prefetch=tf_data_prefetch, tf_data_cache=tf_data_cache,\n",
    "                tf_make_graph=tf_make_graph, jit_compile=jit_compile,\n",
    "               tf_data_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e659632",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = tg_qtr2\n",
    "@tf.function(experimental_compile=False)\n",
    "def run_epoch_numpy():\n",
    "    for batch in range(int(30000 / 500)):\n",
    "        #a = iterator.get_next()\n",
    "        #a = next(iterator)\n",
    "        ix = np.random.randint(low=0, high=self.nrow, size=500)\n",
    "        a = [self.data_num_scaled_cast[ix], self.data_discrete_oh_cast[ix]]\n",
    "        \n",
    "@tf.function(experimental_compile=False)\n",
    "def run_epoch_numpy(iterator):\n",
    "    for batch in range(int(30000 / 500)):\n",
    "        #a = iterator.get_next()\n",
    "        a = next(iterator)\n",
    "        \n",
    "def run_normal():\n",
    "    for b in data_processed:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc4c43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = tf.data.Dataset.zip(\n",
    "    (tf.data.Dataset.from_tensor_slices(tf.cast(tg_qtr.data_num, dtype=tf.float32)),\n",
    "     tf.data.Dataset.from_tensor_slices(tf.cast(tg_qtr.data_discrete_oh, dtype=tf.float32))\n",
    "     )\n",
    ")\n",
    "data_processed = data_processed.shuffle(buffer_size=data_train.shape[0])\n",
    "data_processed = data_processed.repeat(n_epochs).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1216c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comsuming_time 8.6888\n"
     ]
    }
   ],
   "source": [
    "num_epoch=100\n",
    "iterator = iter(tg_qtr.data_processed)\n",
    "t1 = time.time()\n",
    "run_normal()\n",
    "t2 = time.time()\n",
    "print('Comsuming_time %.4f'%(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db4b37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for jit_compile=True: 436.841 seconds\n"
     ]
    }
   ],
   "source": [
    "tg_qtr = TabGAN(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=True)\n",
    "\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(\"jit_compile=True\")\n",
    "    tg_qtr.train(n_epochs, batch_size = batch_size, restart_training = True,\n",
    "             progress_bar=True)\n",
    "    timer_tabGAN.stop(\"jit_compile=True\")\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b28df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518136797897509"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer_tabGAN = utils.timer.load(timer_path)\n",
    "timer_tabGAN.elapsed_time[\"jit_compile=True\"] / timer_tabGAN.elapsed_time[\"jit_compile=False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21a9f34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tabGAN2, jit_compile=False: 334.257 seconds\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False,\n",
    "                 tf_make_train_step_graph=False)\n",
    "\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(\"tabGAN2, jit_compile=False\")\n",
    "    %lprun -f tg_qtr2.train_step_func tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(\"tabGAN2, jit_compile=False\")\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97077847",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17156/4106234316.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhei\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperimental_compile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17156/4106234316.py\u001b[0m in \u001b[0;36mab\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhei\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperimental_compile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhei\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Jaaaaaa\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "class ab():\n",
    "    def __init__(self, hei):\n",
    "        print(hei)\n",
    "        self.hei = True\n",
    "    @tf.function(experimental_compile=self.hei)\n",
    "    def p():\n",
    "        print(\"Jaaaaaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b5a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea3e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c842ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for tabGAN2, jit_compile=False: 303.208 seconds\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False,\n",
    "                 tf_make_train_step_graph=False, use_tf_data=False)\n",
    "\n",
    "if retrain:\n",
    "    timer_tabGAN = utils.timer.load(timer_path)\n",
    "    timer_tabGAN.start(\"tabGAN2, jit_compile=False\")\n",
    "    %lprun -f tg_qtr2.train_step_func tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "    timer_tabGAN.stop(\"tabGAN2, jit_compile=False\")\n",
    "    timer_tabGAN.save(timer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7edd19de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 327.493996 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False)\n",
    "\n",
    "tic()\n",
    "tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6ac071a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 574.917239 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False)\n",
    "\n",
    "tic()\n",
    "tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b2fc82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 572.547649 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False)\n",
    "\n",
    "tic()\n",
    "tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "522d7fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 355.904017 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tg_qtr2 = TabGAN2(data_train, n_critic = n_critic, opt_lr = opt_lr, adam_beta1 = adam_beta1,\n",
    "                quantile_transformation_int = True, quantile_rand_transformation = True,\n",
    "                noise_discrete_unif_max = noise_discrete_unif_max, jit_compile_train_step=False)\n",
    "\n",
    "tic()\n",
    "tg_qtr2.train(n_epochs, batch_size = batch_size, restart_training = True, progress_bar=True)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4186d7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6223776223776224"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "356 / 572"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
