{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b42614",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/work/arneir/ipykernel_2669304/3182675361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantiles_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_share\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import warnings\n",
    "tr.fit(d)\n",
    "print(tr.quantiles_)\n",
    "max_share = 0.5\n",
    "n_quantiles = tr.n_quantiles_\n",
    "col_idx = 0\n",
    "\n",
    "max_n_quantiles_per_category = math.floor(n_quantiles * max_share)\n",
    "if max_n_quantiles_per_category == 0:\n",
    "    warnings.warn(f\"You have chose a max_share={max_share} along with n_quantiles={n_quantiles} such that the maximum number of categories per unique value is less than 1. This is automatically changed such that maximum number of categories per unique value is equal to 1.\")\n",
    "    max_n_quantiles_per_category = 1\n",
    "col_unique_values, col_value_counts = np.unique(tr.quantiles_[:, col_idx], return_counts=True)\n",
    "percentages = col_value_counts / sum(col_value_counts)\n",
    "if max(percentages) > max_share:\n",
    "    indices_too_common_values = np.where(percentages > max_share)[0]\n",
    "    print(\"Too common values:\", col_unique_values[indices_too_common_values])\n",
    "    # Freeing up available quantile spaces from values that are too common\n",
    "    # (have a larger share than permitted by the parameter max_share)\n",
    "    col_bool_remaining_values = np.ones(d[\"a\"].shape[0], dtype=bool)\n",
    "    for curr_common_value_idx in indices_too_common_values:\n",
    "        curr_common_value = col_unique_values[curr_common_value_idx]\n",
    "        curr_common_value_count = col_value_counts[curr_common_value_idx]\n",
    "        n_new_avail_quantiles = curr_common_value_count - max_n_quantiles_per_category\n",
    "        print(\"curr_common_value:\", curr_common_value, \"n_new_avail_quantiles\", n_new_avail_quantiles)\n",
    "        curr_avail_quantile_indices = np.nonzero(np.isclose(tr.quantiles_, curr_common_value))[0][-n_new_avail_quantiles:]\n",
    "        tr.quantiles_[curr_avail_quantile_indices, col_idx] = np.nan\n",
    "        col_bool_remaining_values *= np.logical_not(np.isclose(d[\"a\"], curr_common_value))\n",
    "        \n",
    "    \n",
    "    # Reset the quantile spaces for values with shares smaller than the parameter max_share, before a redraw\n",
    "    col_remaining_values = d[\"a\"].loc[np.logical_not(np.isclose(d[\"a\"],  most_common_value))].to_numpy()\n",
    "    indices_less_common = np.where(percentages <= max_share)\n",
    "    values_less_common = col_unique_values[indices_less_common]\n",
    "    for curr_less_common_value in values_less_common:\n",
    "        print(\"curr_less_common_value\", curr_less_common_value)\n",
    "        tr.quantiles_[np.nonzero(np.isclose(tr.quantiles_, curr_less_common_value))[0], col_idx] = np.nan\n",
    "    \n",
    "    print(tr.quantiles_)\n",
    "    \n",
    "    available_quantile_indices = np.where(np.isnan(tr.quantiles_))[0]\n",
    "    n_available_quantiles = len(available_quantile_indices)\n",
    "    print(\"Available quantile indices\", available_quantile_indices)\n",
    "    print(\"n_available_quantiles:\", n_available_quantiles)\n",
    "    \n",
    "    \n",
    "    print(col_bool_remaining_values)\n",
    "    col_remaining_values = d[\"a\"].loc[col_bool_remaining_values].to_numpy()\n",
    "    print(col_remaining_values)\n",
    "    if col_remaining_values.shape[0] != n_available_quantiles:\n",
    "        print(\"less than\")\n",
    "        # Create empty vector for storing remaining quantiles (both from dataset and interpolated)\n",
    "        temp_new_less_common = np.repeat(np.nan, n_available_quantiles)\n",
    "        \n",
    "        # Initiate remaining dataset values at random places in the empty vector, but with values sorted in ascending order\n",
    "        temp_indices = np.arange(1, n_available_quantiles, dtype=int)\n",
    "        temp_shuffled_indices = np.random.choice(temp_indices, size=temp_indices.shape[0], replace=False)\n",
    "        temp_not_nan_indices = np.sort(temp_shuffled_indices[:col_remaining_values.shape[0]])\n",
    "        temp_nan_indices = temp_shuffled_indices[col_remaining_values.shape[0]:]\n",
    "        \n",
    "        temp_new_less_common[temp_not_nan_indices] = np.sort(col_remaining_values)\n",
    "        # Initiate the remaining places in the vector with linearly interpolated values based on the\n",
    "        # randomly placed (but sorted) values from the dataset.\n",
    "        temp_new_less_common[temp_nan_indices] = np.interp(temp_nan_indices,\n",
    "                                                           temp_not_nan_indices,\n",
    "                                                           temp_new_less_common[temp_not_nan_indices]\n",
    "                                                          )\n",
    "        print(\"temp_new_less_common\")\n",
    "        tr.quantiles_[available_quantile_indices, col_idx] = temp_new_less_common\n",
    "    elif col_remaining_values.shape[0] == n_available_quantiles:\n",
    "        print(\"equal\")\n",
    "        tr.quantiles_[available_quantile_indices, col_idx] = col_remaining_values\n",
    "    else:\n",
    "        print(\"more than\")\n",
    "        tr.quantiles_[available_quantile_indices, col_idx] = np.random.choice(col_remaining_values,\n",
    "                                                                              size=n_available_quantiles, replace=False)\n",
    "    tr.quantiles_[:, col_idx] = np.sort(tr.quantiles_[:, col_idx])\n",
    "\n",
    "print(tr.quantiles_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "tr.fit(d)\n",
    "print(tr.quantiles_)\n",
    "max_share = 0.6\n",
    "n_quantiles = tr.n_quantiles_\n",
    "col_idx = 0\n",
    "\n",
    "max_n_quantiles_per_value = math.floor(n_quantiles * max_share)\n",
    "print(\"max quantiles\", max_n_quantiles_per_value)\n",
    "if max_n_quantiles_per_value == 0:\n",
    "    warnings.warn(f\"You have chose a max_share={max_share} along with n_quantiles={n_quantiles} such that the maximum number of categories per unique value is less than 1. This is automatically changed such that maximum number of categories per unique value is equal to 1.\")\n",
    "    max_n_quantiles_per_value = 1\n",
    "col_unique_values, col_value_counts = np.unique(tr.quantiles_[:, col_idx], return_counts=True)\n",
    "col_percentages = col_value_counts / sum(col_value_counts)\n",
    "print(\"col_percentages\", col_percentages)\n",
    "if max(col_percentages) > max_share:\n",
    "    indices_too_common_values = np.where(col_percentages > max_share)[0]\n",
    "    print(\"Too common values:\", col_unique_values[indices_too_common_values])\n",
    "    # Freeing up available quantile spaces from values that are too common\n",
    "    # (have a larger share than permitted by the parameter max_share)\n",
    "    col_bool_remaining_values = np.ones(d[\"a\"].shape[0], dtype=bool)\n",
    "    for curr_common_value_idx in indices_too_common_values:\n",
    "        curr_common_value = col_unique_values[curr_common_value_idx]\n",
    "        curr_common_value_count = col_value_counts[curr_common_value_idx]\n",
    "        print(\"curr_common_value:\", curr_common_value, \"n_new_avail_quantiles\", n_new_avail_quantiles)\n",
    "        curr_avail_quantile_indices = np.nonzero(\n",
    "            np.isclose(tr.quantiles_[:, col_idx], curr_common_value)\n",
    "        )[0][max_n_quantiles_per_value:]\n",
    "        print(\"curr_avail_ind\", curr_avail_quantile_indices)\n",
    "        tr.quantiles_[curr_avail_quantile_indices, col_idx] = np.nan\n",
    "        col_bool_remaining_values *= np.logical_not(np.isclose(d[\"a\"], curr_common_value))\n",
    "        \n",
    "    \n",
    "    # Reset the quantile spaces for values with shares smaller than the parameter max_share, before a redraw\n",
    "    indices_less_common = np.where(col_percentages <= max_share)\n",
    "    values_less_common = col_unique_values[indices_less_common]\n",
    "    for curr_less_common_value in values_less_common:\n",
    "        print(\"curr_less_common_value\", curr_less_common_value)\n",
    "        tr.quantiles_[np.nonzero(np.isclose(tr.quantiles_, curr_less_common_value))[0], col_idx] = np.nan\n",
    "    \n",
    "    print(tr.quantiles_)\n",
    "    \n",
    "    available_quantile_indices = np.where(np.isnan(tr.quantiles_))[0]\n",
    "    n_available_quantiles = len(available_quantile_indices)\n",
    "    print(\"Available quantile indices\", available_quantile_indices)\n",
    "    print(\"n_available_quantiles:\", n_available_quantiles)\n",
    "    \n",
    "    print(col_bool_remaining_values)\n",
    "    col_remaining_values = d[\"a\"].loc[col_bool_remaining_values].to_numpy()\n",
    "    print(col_remaining_values)\n",
    "    if col_remaining_values.shape[0] != n_available_quantiles:\n",
    "        tr.quantiles_[available_quantile_indices, col_idx] = np.nanpercentile(col_remaining_values,\n",
    "                                                                              q=np.linspace(0, 100, n_available_quantiles))\n",
    "    else:\n",
    "        print(\"equal\")\n",
    "        tr.quantiles_[available_quantile_indices, col_idx] = col_remaining_values\n",
    "    \n",
    "    tr.quantiles_[:, col_idx] = np.sort(tr.quantiles_[:, col_idx])\n",
    "\n",
    "print(tr.quantiles_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
